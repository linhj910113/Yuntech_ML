{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d6e04792",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:59:54.576561Z",
     "start_time": "2021-06-18T15:59:54.558608Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "import jieba.analyse\n",
    "import string\n",
    "import xgboost as xgb\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV,train_test_split\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from tensorflow.python.keras.preprocessing import text, sequence\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier \n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.python.keras.preprocessing import text, sequence\n",
    "from tensorflow.python.keras.layers import Dense, Input, Flatten, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa9a5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:44:56.415735Z",
     "start_time": "2021-06-18T13:44:56.073217Z"
    }
   },
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import logging\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import re\n",
    "import jieba\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, train_test_split, cross_validate, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB  \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier \n",
    "import xgboost as xgb\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras import layers, models, optimizers\n",
    "from tensorflow.python.keras.layers import Conv1D, MaxPooling1D, Embedding\n",
    "from tensorflow.python.keras.preprocessing import text, sequence\n",
    "from tensorflow.python.keras.layers import Dense, Input, Flatten, Dropout, LSTM, BatchNormalization\n",
    "from tensorflow.python.keras import Sequential\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86bd1146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:54:46.235877Z",
     "start_time": "2021-06-18T13:54:46.206978Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df=pd.read_csv(\"train_csv.csv\")\n",
    "test_df=pd.read_csv(\"test_csv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da5024bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:54:49.080421Z",
     "start_time": "2021-06-18T13:54:46.784930Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-b94d56eafe0d>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"text\"][i] = jieba.cut(train_df[\"text\"][i], cut_all=False)\n",
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\candy\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.525 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "<ipython-input-3-b94d56eafe0d>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df[\"text\"][i] = ' '.join(train_df[\"text\"][i])\n",
      "<ipython-input-3-b94d56eafe0d>:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"text\"][i] = jieba.cut(test_df[\"text\"][i], cut_all=False)\n",
      "<ipython-input-3-b94d56eafe0d>:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df[\"text\"][i] = ' '.join(test_df[\"text\"][i])\n"
     ]
    }
   ],
   "source": [
    "# 訓練資料集做斷句\n",
    "for i in range(len(train_df)):\n",
    "    train_df[\"text\"][i] = jieba.cut(train_df[\"text\"][i], cut_all=False)\n",
    "    train_df[\"text\"][i] = ' '.join(train_df[\"text\"][i])\n",
    "    \n",
    "#     train_df[\"text\"][i] = jieba.lcut(train_df[\"text\"][i], cut_all = False)\n",
    "#     train_df[\"text\"][i] = ''.join([i for i in train_df[\"text\"][i] if i not in string.punctuation])\n",
    "    \n",
    "# 訓練資料集做斷句\n",
    "for i in range(len(test_df)):\n",
    "    test_df[\"text\"][i] = jieba.cut(test_df[\"text\"][i], cut_all=False)\n",
    "    test_df[\"text\"][i] = ' '.join(test_df[\"text\"][i])\n",
    "    \n",
    "#     test_df[\"text\"][i] = jieba.lcut(test_df[\"text\"][i], cut_all = False)\n",
    "#     test_df[\"text\"][i] = ''.join([i for i in test_df[\"text\"][i] if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79f5ab2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:54:50.215988Z",
     "start_time": "2021-06-18T13:54:50.195042Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>wav</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>000207.wav</td>\n",
       "      <td>7</td>\n",
       "      <td>e10 鋁圈 單後紅 夫人 英文 鳳姐 你 今兒 什麼 樣鳳姐 兒到 太太 只管 請 回去 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000276.wav</td>\n",
       "      <td>5</td>\n",
       "      <td>取締 酒後駕 車勤務 進行 呼氣質 酒測 時會議 警政署 訂 單取 締酒 後 駕車 作業 程...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000748.wav</td>\n",
       "      <td>4</td>\n",
       "      <td>致伸 縮喇家 在 五台山 跟師 父子 增長 老學會 說 因緣 經驗 你 可將 女兒 長 了 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>001111.wav</td>\n",
       "      <td>1</td>\n",
       "      <td>寄 之 盲校 被叫 姊親 自去 接 又 叫 我 先 回公館裡 去 知道 我 就 先回去 了 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>001206.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>關於難 辭 其者 自身 也 為 孫權 所 砂石 半年 的 攻防 戰中數 中景 不 派兵 網雲...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>924</td>\n",
       "      <td>554319.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>10.28 天安 門 事件 2013 年 10 月 28 日 12   10   05 分 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>925</td>\n",
       "      <td>564067.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>不同 地方 對滅 火器 的 分類 稍 有 不同 但 基本上 都 是 按照 火 的 種類 分為...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>926</td>\n",
       "      <td>564652.wav</td>\n",
       "      <td>2</td>\n",
       "      <td>董卓 時常 使 人 探 聽 是 日 獲得此 詩來 成 董卓 著樂 願望 作師 沙織 有名 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>927</td>\n",
       "      <td>609270.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>台灣 雨量 豐沛 大小 河川 1 部長 度 超過 100 公里 有 7 條一試 分別 是 濁...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>928</td>\n",
       "      <td>654319.wav</td>\n",
       "      <td>3</td>\n",
       "      <td>天安 門 事件 是 指 在 不同 時期 發生 在 中國 北京 天安 門廣場 的 政治 事件 ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>929 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index         wav  label  \\\n",
       "0        0  000207.wav      7   \n",
       "1        1  000276.wav      5   \n",
       "2        2  000748.wav      4   \n",
       "3        3  001111.wav      1   \n",
       "4        4  001206.wav      3   \n",
       "..     ...         ...    ...   \n",
       "924    924  554319.wav      3   \n",
       "925    925  564067.wav      3   \n",
       "926    926  564652.wav      2   \n",
       "927    927  609270.wav      3   \n",
       "928    928  654319.wav      3   \n",
       "\n",
       "                                                  text  \n",
       "0    e10 鋁圈 單後紅 夫人 英文 鳳姐 你 今兒 什麼 樣鳳姐 兒到 太太 只管 請 回去 ...  \n",
       "1    取締 酒後駕 車勤務 進行 呼氣質 酒測 時會議 警政署 訂 單取 締酒 後 駕車 作業 程...  \n",
       "2    致伸 縮喇家 在 五台山 跟師 父子 增長 老學會 說 因緣 經驗 你 可將 女兒 長 了 ...  \n",
       "3    寄 之 盲校 被叫 姊親 自去 接 又 叫 我 先 回公館裡 去 知道 我 就 先回去 了 ...  \n",
       "4    關於難 辭 其者 自身 也 為 孫權 所 砂石 半年 的 攻防 戰中數 中景 不 派兵 網雲...  \n",
       "..                                                 ...  \n",
       "924  10.28 天安 門 事件 2013 年 10 月 28 日 12   10   05 分 ...  \n",
       "925  不同 地方 對滅 火器 的 分類 稍 有 不同 但 基本上 都 是 按照 火 的 種類 分為...  \n",
       "926  董卓 時常 使 人 探 聽 是 日 獲得此 詩來 成 董卓 著樂 願望 作師 沙織 有名 1...  \n",
       "927  台灣 雨量 豐沛 大小 河川 1 部長 度 超過 100 公里 有 7 條一試 分別 是 濁...  \n",
       "928  天安 門 事件 是 指 在 不同 時期 發生 在 中國 北京 天安 門廣場 的 政治 事件 ...  \n",
       "\n",
       "[929 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043afd50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T13:55:01.877601Z",
     "start_time": "2021-06-18T13:55:01.859649Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_df['text'], train_df['label'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "be4d493b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T16:51:53.683272Z",
     "start_time": "2021-06-18T16:51:53.672302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "381    6\n",
       "499    2\n",
       "97     0\n",
       "250    1\n",
       "198    4\n",
       "      ..\n",
       "106    6\n",
       "270    1\n",
       "860    5\n",
       "435    4\n",
       "102    4\n",
       "Name: label, Length: 743, dtype: int64"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0310ce33",
   "metadata": {},
   "source": [
    "# TF-IDF Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1dcff9ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:48:42.534995Z",
     "start_time": "2021-06-18T15:48:42.477141Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<743x314 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', min_df=10)\n",
    "tfidf_vect.fit_transform(train_df['text'])\n",
    "tfidf_train = TfidfVectorizer(vocabulary=tfidf_vect.vocabulary_).fit_transform(X_train)\n",
    "tfidf_test = TfidfVectorizer(vocabulary=tfidf_vect.vocabulary_).fit_transform(X_test)\n",
    "tfidf_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8228ad2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:46:01.956796Z",
     "start_time": "2021-06-18T15:46:01.944827Z"
    }
   },
   "source": [
    "## IT-IDF + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eefc5f39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:47:32.416000Z",
     "start_time": "2021-06-18T15:47:31.542524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================  Score on TFIDF feature  ========================================\n",
      "Score on Train:  0.65814266487214\n",
      "Score on Test:  0.46774193548387094\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(max_iter=10, n_jobs=-1)   \n",
    "clf.fit(tfidf_train, y_train)\n",
    "\n",
    "print('='*40, ' Score on TFIDF feature ', '='*40)\n",
    "print('Score on Train: ', metrics.accuracy_score(y_train, clf.predict(tfidf_train)))\n",
    "print('Score on Test: ', metrics.accuracy_score(y_test, clf.predict(tfidf_test)))\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ad3ec0",
   "metadata": {},
   "source": [
    "## IT-IDF + XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "42505148",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:48:08.022711Z",
     "start_time": "2021-06-18T15:48:05.263481Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\candy\\anaconda3\\envs\\ML\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:48:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:573: \n",
      "Parameters: { \"silent\" } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[23:48:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "========================================  Score on TFIDF feature  ========================================\n",
      "Score on Train:  0.8438761776581427\n",
      "Score on Test:  0.41397849462365593\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier(n_estimators=500, objective='multi:softmax', n_jobs=-1, silent=False)\n",
    "clf.fit(tfidf_train, y_train)\n",
    "print('='*40, ' Score on TFIDF feature ', '='*40)\n",
    "print('Score on Train: ', metrics.accuracy_score(y_train, clf.predict(tfidf_train)))\n",
    "print('Score on Test: ', metrics.accuracy_score(y_test, clf.predict(tfidf_test)))\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6ad1ef",
   "metadata": {},
   "source": [
    "## IT-IDF + RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adb234fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:50:38.526865Z",
     "start_time": "2021-06-18T15:50:37.659186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================  Score on TFIDF feature  ========================================\n",
      "Score on Train:  0.8640646029609691\n",
      "Score on Test:  0.4838709677419355\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 500, max_features = 'sqrt', n_jobs=-1, random_state = 10)  \n",
    "clf.fit(tfidf_train, y_train)\n",
    "print('='*40, ' Score on TFIDF feature ', '='*40)\n",
    "print('Score on Train: ', metrics.accuracy_score(y_train, clf.predict(tfidf_train)))\n",
    "print('Score on Test: ', metrics.accuracy_score(y_test, clf.predict(tfidf_test)))\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19e18c",
   "metadata": {},
   "source": [
    "## IT-IDF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "838b19ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T16:54:50.320996Z",
     "start_time": "2021-06-18T16:54:42.906702Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================  Score on TFIDF feature  ========================================\n",
      "Score on Train:  1.0\n",
      "Score on Test:  0.6559139784946236\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear',C=2.0)\n",
    "clf.fit(tfidf_train, y_train)\n",
    "print('='*40, ' Score on TFIDF feature ', '='*40)\n",
    "print('Score on Train: ', metrics.accuracy_score(y_train, clf.predict(tfidf_train)))\n",
    "print('Score on Test: ', metrics.accuracy_score(y_test, clf.predict(tfidf_test)))\n",
    "print('='*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18063973",
   "metadata": {},
   "source": [
    "## IT-IDF + NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "16ff1c12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:54:36.006008Z",
     "start_time": "2021-06-18T15:54:35.862440Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================  Score on CV result  ========================================\n",
      "Best Score:  0.5019227280972247\n",
      "Best Params:  {'alpha': 0.6}\n",
      "========================================  Score on TFIDF feature  ========================================\n",
      "Score on Train:  0.6500672947510094\n",
      "Score on Test:  0.45161290322580644\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'alpha':[1.4, 1.2, 1, 0.8, 0.6]}\n",
    "estimators = GridSearchCV(estimator = MultinomialNB(),\n",
    "                      param_grid = param_grid,\n",
    "                      n_jobs = -1,\n",
    "                      cv = 5)\n",
    "estimators.fit(tfidf_train, y_train)\n",
    "print('='*40, ' Score on CV result ', '='*40)\n",
    "print('Best Score: ', estimators.best_score_)\n",
    "print('Best Params: ', estimators.best_params_)\n",
    "\n",
    "clf = MultinomialNB(alpha = estimators.best_params_['alpha'])   \n",
    "clf.fit(tfidf_train, y_train)\n",
    "print('='*40, ' Score on TFIDF feature ', '='*40)\n",
    "print('Score on Train: ', metrics.accuracy_score(y_train, clf.predict(tfidf_train)))\n",
    "print('Score on Test: ', metrics.accuracy_score(y_test, clf.predict(tfidf_test)))\n",
    "print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec68b6f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:45:30.918966Z",
     "start_time": "2021-06-18T15:45:30.913948Z"
    }
   },
   "source": [
    "# CountVector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5fe14c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T15:43:34.068739Z",
     "start_time": "2021-06-18T15:43:34.014608Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<743x314 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 2028 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}', min_df=10)\n",
    "count_vect.fit(train_df['text'])\n",
    "counts_train = CountVectorizer(vocabulary=count_vect.vocabulary_).fit_transform(X_train)\n",
    "counts_test = CountVectorizer(vocabulary=count_vect.vocabulary_).fit_transform(X_test)\n",
    "counts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c4ff150",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:04:39.010293Z",
     "start_time": "2021-06-18T17:04:38.992687Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>不要 tpp 是否 會 影響 新 南向 政策 的 推動十 楊國鑫 回應 美國 對 於 tpp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>你 用 手帕 蒙著 臉 叫 我 女兒 從 你 面前 過你 抓住 哪個 就 把 哪個 配給 你...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>紀氏話 說 得 高興 站 在 旁邊 站 著 等 說 完 的 話 才 走 進 一步 回到 剛才...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>長 沙 途中 遭 荊州 劉表 11 級 生間 為 此 與劉 表姊 院後發兵 進攻 荊州 不料...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>致伸 縮灑家 是 五台山 的 和尚 要 去 東京公幹 今晚 趕不上 樹頭 解櫃 裝戰術 一夜...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>817</td>\n",
       "      <td>超約 莫非 以 超乎 朝 曰 此 乃 無謀 之輩名 東和足率 也 操 又 曰 理鍋 2 則此...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>818</td>\n",
       "      <td>老 怪 一口 吃進 問會 唱 嗎 小龍 就 唱 了 一首 小曲 兒老怪 又 問會舞 嗎 小龍...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>819</td>\n",
       "      <td>設 明天 奶是 保育 的 一個 得 用 的 切要 年 輕 不 暗示 是 如 聽 聽 講說 金...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>820</td>\n",
       "      <td>鬼蝠 魟 署轄下 有 兩個 物種 一種 是 珊瑚礁 型 的 差 是 前口蝠 鱝 另 一種則 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>821</td>\n",
       "      <td>不是 也 非 道路 曰 我 本 不 與 答 你 你 把 呂布來 下 我 我 偏要 打 你 我...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index                                               text\n",
       "0        0  不要 tpp 是否 會 影響 新 南向 政策 的 推動十 楊國鑫 回應 美國 對 於 tpp...\n",
       "1        1  你 用 手帕 蒙著 臉 叫 我 女兒 從 你 面前 過你 抓住 哪個 就 把 哪個 配給 你...\n",
       "2        2  紀氏話 說 得 高興 站 在 旁邊 站 著 等 說 完 的 話 才 走 進 一步 回到 剛才...\n",
       "3        3  長 沙 途中 遭 荊州 劉表 11 級 生間 為 此 與劉 表姊 院後發兵 進攻 荊州 不料...\n",
       "4        4  致伸 縮灑家 是 五台山 的 和尚 要 去 東京公幹 今晚 趕不上 樹頭 解櫃 裝戰術 一夜...\n",
       "..     ...                                                ...\n",
       "817    817  超約 莫非 以 超乎 朝 曰 此 乃 無謀 之輩名 東和足率 也 操 又 曰 理鍋 2 則此...\n",
       "818    818  老 怪 一口 吃進 問會 唱 嗎 小龍 就 唱 了 一首 小曲 兒老怪 又 問會舞 嗎 小龍...\n",
       "819    819  設 明天 奶是 保育 的 一個 得 用 的 切要 年 輕 不 暗示 是 如 聽 聽 講說 金...\n",
       "820    820  鬼蝠 魟 署轄下 有 兩個 物種 一種 是 珊瑚礁 型 的 差 是 前口蝠 鱝 另 一種則 ...\n",
       "821    821  不是 也 非 道路 曰 我 本 不 與 答 你 你 把 呂布來 下 我 我 偏要 打 你 我...\n",
       "\n",
       "[822 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4366611",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4240a7b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:56.919774Z",
     "start_time": "2021-06-18T17:33:52.952692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12654 unique tokens.\n",
      "Shape of tfidf_train tensor: (743, 10000)\n",
      "Shape of tfidf_test tensor: (186, 10000)\n",
      "Shape of y_train tensor: (743, 8)\n",
      "Shape of y_test tensor: (186, 8)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               5120512   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 64)                256       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 8)                 136       \n",
      "=================================================================\n",
      "Total params: 5,564,408\n",
      "Trainable params: 5,561,400\n",
      "Non-trainable params: 3,008\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "5/5 [==============================] - 2s 86ms/step - loss: 2.2660 - accuracy: 0.2166 - val_loss: 1.6490 - val_accuracy: 0.4564\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.6488 - accuracy: 0.9216 - val_loss: 1.3910 - val_accuracy: 0.5839\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 41ms/step - loss: 0.3633 - accuracy: 0.9987 - val_loss: 1.2358 - val_accuracy: 0.6107\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.2337 - accuracy: 1.0000 - val_loss: 1.1558 - val_accuracy: 0.6242\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.1600 - accuracy: 0.9987 - val_loss: 1.1145 - val_accuracy: 0.6510\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.1127 - accuracy: 1.0000 - val_loss: 1.0970 - val_accuracy: 0.6376\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0885 - accuracy: 1.0000 - val_loss: 1.0873 - val_accuracy: 0.6376\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 42ms/step - loss: 0.0706 - accuracy: 1.0000 - val_loss: 1.0787 - val_accuracy: 0.6309\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 45ms/step - loss: 0.0583 - accuracy: 1.0000 - val_loss: 1.0756 - val_accuracy: 0.6376\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 43ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 1.0708 - val_accuracy: 0.6309\n",
      "Epoch 00010: early stopping\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2664 - accuracy: 0.6129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2663668394088745, 0.6129032373428345]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 超參數設定\n",
    "LEARNING_RATE = 1e-3\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 128\n",
    "MOMENTUM = 0.95\n",
    "# 建立資料格式\n",
    "# 考量時間與記憶體容量，僅保留數量最多的1萬個詞\n",
    "tokenizer = text.Tokenizer(num_words=10000) \n",
    "tokenizer.fit_on_texts(train_df['text'])\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "tfidf_train = tokenizer.texts_to_sequences(X_train) \n",
    "tfidf_train = tokenizer.sequences_to_matrix(tfidf_train, mode='tfidf')\n",
    "tfidf_test = tokenizer.texts_to_sequences(X_test)\n",
    "tfidf_test = tokenizer.sequences_to_matrix(tfidf_test, mode='tfidf')\n",
    "print('Shape of tfidf_train tensor:', tfidf_train.shape)\n",
    "print('Shape of tfidf_test tensor:', tfidf_test.shape)\n",
    "\n",
    "y_train_dummy = to_categorical(np.asarray(y_train))\n",
    "y_test_dummy = to_categorical(np.asarray(y_test))\n",
    "print('Shape of y_train tensor:', y_train_dummy.shape)\n",
    "print('Shape of y_test tensor:', y_test_dummy.shape)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "model = Sequential()\n",
    "model.add(Dense(units=512, input_shape=(tfidf_train.shape[1],), activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(512, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(128, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(32, activation='elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(16, activation='elu'))\n",
    "model.add(Dense(y_train_dummy.shape[1], activation='softmax'))\n",
    "model.summary()\n",
    "# 載入 Callbacks, 並將 monitor 設定為監控 validation loss\n",
    "earlystop = EarlyStopping(monitor=\"val_accuracy\", \n",
    "                        patience=5, \n",
    "                        verbose=1)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "            optimizer=optimizers.Adam(lr=LEARNING_RATE, epsilon=None, decay=0.0),\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "model.fit(tfidf_train, y_train_dummy,\n",
    "        epochs=EPOCHS, \n",
    "        validation_split=0.2,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        callbacks=[earlystop])\n",
    "model.evaluate(tfidf_test, y_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "db0e93bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:57.011546Z",
     "start_time": "2021-06-18T17:33:56.920749Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_val = tokenizer.texts_to_sequences(test_df[\"text\"]) \n",
    "tfidf_val = tokenizer.sequences_to_matrix(tfidf_val, mode='tfidf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5c27cadd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:57.274326Z",
     "start_time": "2021-06-18T17:33:57.012511Z"
    }
   },
   "outputs": [],
   "source": [
    "y_test_predicted=model.predict(tfidf_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "275019b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:57.289286Z",
     "start_time": "2021-06-18T17:33:57.275323Z"
    }
   },
   "outputs": [],
   "source": [
    "temp=np.argmax(y_test_predicted,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c3de50e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:58.219048Z",
     "start_time": "2021-06-18T17:33:58.210073Z"
    }
   },
   "outputs": [],
   "source": [
    "temp=pd.DataFrame(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "15f6a709",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:58.405842Z",
     "start_time": "2021-06-18T17:33:58.392852Z"
    }
   },
   "outputs": [],
   "source": [
    "temp.to_csv(\"temp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d1f4a497",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T17:33:58.714742Z",
     "start_time": "2021-06-18T17:33:58.694841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>817</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>822 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    5\n",
       "1    3\n",
       "2    1\n",
       "3    2\n",
       "4    4\n",
       "..  ..\n",
       "817  2\n",
       "818  6\n",
       "819  1\n",
       "820  1\n",
       "821  2\n",
       "\n",
       "[822 rows x 1 columns]"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade99d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77d900d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c957e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fb53bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c18c3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f3d205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a48b86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50251fbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced5bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f69e19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f35ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298336eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d31e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc1557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821e945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbec4ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4660c1bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73c4c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76adde6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323a01f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd13d34c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8896686d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94e2832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b9a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a18df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7869cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce8d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
